{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da62680-7c8d-4dca-9311-da3adf3dea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4de4ea1-75f1-45ba-b29c-17651a08b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d986f7-6da1-4c54-8c42-ada2a4e5d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_zones = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab7f205-ab3d-4c68-a7b1-3482441840ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv(url_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72940e2-0726-497b-b8a3-cde8d4a27fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f98623-a649-4ecf-8c05-983b98ed93ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocationID      int64\n",
       "Borough           str\n",
       "Zone              str\n",
       "service_zone      str\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52942b5a-7db8-46fe-99d6-23a8620f55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da104ed3-a974-42b6-9419-bd44ee2fc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6aa6e1a1-e029-42dc-b798-ce839391797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_november_2025 = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-11.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9ca4d62-ec1d-4e13-b9d7-05cae3967de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url_november_2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "991ac3fa-57fa-4b6c-9a61-4951d4b5dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_like_object = io.BytesIO(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "520c0eb1-3b8e-4f29-a90d-85b3e26739a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = pq.ParquetFile(file_like_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbafe282-6b15-429d-a11b-aff079dc3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47b57750-9c62-47bf-8737-4420fd99318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "100000\n",
      "81444\n"
     ]
    }
   ],
   "source": [
    "for batch in parquet_file.iter_batches(batch_size=chunksize):\n",
    "    df_chunk = batch.to_pandas()\n",
    "    print(len(df_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fd861-5060-4bd7-b63b-8c58fc4b39c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e1fd37d-4ad7-4b83-a427-f21584348ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb5 in position 19: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_iter = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl_november_2025\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100000\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data-engineering-zoomcamp-docker-terraform/pipeline/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data-engineering-zoomcamp-docker-terraform/pipeline/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:300\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    297\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data-engineering-zoomcamp-docker-terraform/pipeline/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1645\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1644\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data-engineering-zoomcamp-docker-terraform/pipeline/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1922\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1919\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1921\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1922\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1923\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data-engineering-zoomcamp-docker-terraform/pipeline/.venv/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:95\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     94\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     99\u001b[39m passed_names = \u001b[38;5;28mself\u001b[39m.names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:568\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:657\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._get_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:868\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:885\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2076\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:325\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xb5 in position 19: invalid start byte"
     ]
    }
   ],
   "source": [
    "df_iter = pd.read_csv(\n",
    "    url_november_2025,\n",
    "    dtype=dtype,\n",
    "    parse_dates=parse_dates,\n",
    "    iterator=True,\n",
    "    chunksize=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b98fdb-f276-4af6-9126-704325c39af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc0b861f-a371-4d23-a4f0-5acfbaaa6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(url_november_2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6245ee0-140b-4d28-80ba-485633dda401",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e2a6dce-def3-466a-aa73-3d25bf879998",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_table() got an unexpected keyword argument 'iterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_iter = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m       \u001b[49m\u001b[43murl_november_2025\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m       \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m       \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m   \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data-engineering-zoomcamp-docker-terraform/pipeline/.venv/lib/python3.13/site-packages/pandas/io/parquet.py:671\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, dtype_backend, filesystem, filters, to_pandas_kwargs, **kwargs)\u001b[39m\n\u001b[32m    668\u001b[39m impl = get_engine(engine)\n\u001b[32m    669\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mto_pandas_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto_pandas_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/data-engineering-zoomcamp-docker-terraform/pipeline/.venv/lib/python3.13/site-packages/pandas/io/parquet.py:260\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, dtype_backend, storage_options, filesystem, to_pandas_kwargs, **kwargs)\u001b[39m\n\u001b[32m    253\u001b[39m path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[32m    254\u001b[39m     path,\n\u001b[32m    255\u001b[39m     filesystem,\n\u001b[32m    256\u001b[39m     storage_options=storage_options,\n\u001b[32m    257\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    258\u001b[39m )\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     pa_table = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparquet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n\u001b[32m    268\u001b[39m         filterwarnings(\n\u001b[32m    269\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    270\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmake_block is deprecated\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    271\u001b[39m             Pandas4Warning,\n\u001b[32m    272\u001b[39m         )\n",
      "\u001b[31mTypeError\u001b[39m: read_table() got an unexpected keyword argument 'iterator'"
     ]
    }
   ],
   "source": [
    " df_iter = pd.read_parquet(\n",
    "        url_november_2025,\n",
    "        iterator=True,\n",
    "        chunksize=chunksize\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df00fa9b-b7af-46aa-b08d-5ef502d82ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>cbd_congestion_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2025-11-01 00:13:25</td>\n",
       "      <td>2025-11-01 00:13:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.15</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 00:49:07</td>\n",
       "      <td>2025-11-01 01:01:22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.94</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-01 00:07:19</td>\n",
       "      <td>2025-11-01 00:20:41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.62</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-11-01 00:00:00</td>\n",
       "      <td>2025-11-01 01:01:03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>66.7</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.14</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-11-01 00:18:50</td>\n",
       "      <td>2025-11-01 00:49:32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>39.4</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         7  2025-11-01 00:13:25   2025-11-01 00:13:25              1.0   \n",
       "1         2  2025-11-01 00:49:07   2025-11-01 01:01:22              1.0   \n",
       "2         1  2025-11-01 00:07:19   2025-11-01 00:20:41              0.0   \n",
       "3         2  2025-11-01 00:00:00   2025-11-01 01:01:03              3.0   \n",
       "4         1  2025-11-01 00:18:50   2025-11-01 00:49:32              0.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           1.68         1.0                  N            43           186   \n",
       "1           2.28         1.0                  N           142           237   \n",
       "2           2.70         1.0                  N           163           238   \n",
       "3          12.87         1.0                  N           138           261   \n",
       "4           8.40         1.0                  N           138            37   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         14.9   0.00      0.5        1.50          0.00   \n",
       "1             1         14.2   1.00      0.5        4.99          0.00   \n",
       "2             1         15.6   4.25      0.5        4.27          0.00   \n",
       "3             1         66.7   6.00      0.5        0.00          6.94   \n",
       "4             2         39.4   7.75      0.5        0.00          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
       "0                    1.0         22.15                   2.5         0.00   \n",
       "1                    1.0         24.94                   2.5         0.00   \n",
       "2                    1.0         25.62                   2.5         0.00   \n",
       "3                    1.0         86.14                   2.5         1.75   \n",
       "4                    1.0         48.65                   0.0         1.75   \n",
       "\n",
       "   cbd_congestion_fee  \n",
       "0                0.75  \n",
       "1                0.75  \n",
       "2                0.75  \n",
       "3                0.75  \n",
       "4                0.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2789019b-554d-4c53-ad72-ad7f7f5113ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int32\n",
       "tpep_pickup_datetime     datetime64[us]\n",
       "tpep_dropoff_datetime    datetime64[us]\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "RatecodeID                      float64\n",
       "store_and_fwd_flag                  str\n",
       "PULocationID                      int32\n",
       "DOLocationID                      int32\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "Airport_fee                     float64\n",
       "cbd_congestion_fee              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "035fae76-18dc-4490-bc96-9078acead012",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/'\n",
    "df = pd.read_csv(prefix + 'yellow_tripdata_2021-01.csv.gz', nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2bf8e05-5277-4f0f-9625-ecfacd60290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = prefix + 'yellow_tripdata_2021-01.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3605ca53-223f-4876-84cf-3e07fee576df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    \"VendorID\": \"Int64\",\n",
    "    \"passenger_count\": \"Int64\",\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"RatecodeID\": \"Int64\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "    \"PULocationID\": \"Int64\",\n",
    "    \"DOLocationID\": \"Int64\",\n",
    "    \"payment_type\": \"Int64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"extra\": \"float64\",\n",
    "    \"mta_tax\": \"float64\",\n",
    "    \"tip_amount\": \"float64\",\n",
    "    \"tolls_amount\": \"float64\",\n",
    "    \"improvement_surcharge\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"congestion_surcharge\": \"float64\"\n",
    "}\n",
    "\n",
    "parse_dates = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    prefix + 'yellow_tripdata_2021-01.csv.gz',\n",
    "    nrows=100,\n",
    "    dtype=dtype,\n",
    "    parse_dates=parse_dates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "426f978c-cf1e-49e5-80dd-dc6cec9ca6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecc5b600-b5ec-47cc-928c-80651a86c69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213a2ef8-51f1-44d6-8802-6c72d6211fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcec8f60-ffa2-44aa-9feb-544071baf6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv(url,\n",
    "    dtype=dtype,\n",
    "    parse_dates=parse_dates,\n",
    "    iterator=True,\n",
    "    chunksize=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "313d52da-7c13-4a34-808d-f129321dac53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3067111ed63b438597bb4beba3ca4baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 100000\n",
      "Inserted: 69765\n"
     ]
    }
   ],
   "source": [
    "first = True\n",
    "\n",
    "for df_chunk in tqdm(df_iter):\n",
    "\n",
    "    if first:\n",
    "        # Create table schema (no data)\n",
    "        df_chunk.head(0).to_sql(\n",
    "            name=\"yellow_taxi_data\",\n",
    "            con=engine,\n",
    "            if_exists=\"replace\"\n",
    "        )\n",
    "        first = False\n",
    "        print(\"Table created\")\n",
    "\n",
    "    # Insert chunk\n",
    "    df_chunk.to_sql(\n",
    "        name=\"yellow_taxi_data\",\n",
    "        con=engine,\n",
    "        if_exists=\"append\"\n",
    "    )\n",
    "\n",
    "    print(\"Inserted:\", len(df_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc34c0-72dd-4822-8929-49e6460dc31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
